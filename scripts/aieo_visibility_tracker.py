"""AIEO Visibility Pulse è‡ªå‹•åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ"""

import csv
import json
import os
from dataclasses import dataclass
from datetime import datetime, timezone
from typing import List, Dict, Any

import matplotlib
import pandas as pd
import requests

# ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ç’°å¢ƒã§ã®Matplotlibåˆ©ç”¨ã‚’å®‰å®šã•ã›ã‚‹ãŸã‚ã®è¨­å®š
matplotlib.use("Agg")
import matplotlib.pyplot as plt  # noqa: E402  # é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’æ˜ç¤º


@dataclass
class SearchResult:
    """Googleæ¤œç´¢çµæœ1ä»¶ã‚’è¡¨ã™ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""

    title: str
    url: str


# === è¨­å®šå€¤ ===
VISIBILITY_LOG = "visibility_log.csv"
RESonANCE_CHART = "resonance_chart.png"
TREND_CHART = "visibility_chart.png"
GROWTH_CHART = "visibility_growth_rate.png"
DEFAULT_KEYWORDS = ["KGNINJA", "KGNINJA AI", "FuwaCoco", "Psycho-Frame", "AIEO"]
MEMORY_FILE = "aieo_memory.json"


# === ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° ===
def load_keywords() -> List[str]:
    """è¿½è·¡å¯¾è±¡ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è¦§ã‚’å–å¾—ï¼ˆç’°å¢ƒå¤‰æ•° â†’ ãƒ¡ãƒ¢ãƒªãƒ•ã‚¡ã‚¤ãƒ« â†’ æ—¢å®šå€¤ã®é †ï¼‰"""

    # ç’°å¢ƒå¤‰æ•°å„ªå…ˆï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰
    env_keywords = os.getenv("AIEO_KEYWORDS")
    if env_keywords:
        # æ—¥æœ¬èªã‚³ãƒ¡ãƒ³ãƒˆ: æ‰‹å…¥åŠ›ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å„ªå…ˆã—ã€ç©ºæ–‡å­—ã‚’é™¤å¤–
        keywords = [kw.strip() for kw in env_keywords.split(",") if kw.strip()]
        if keywords:
            return keywords

    # ãƒ¡ãƒ¢ãƒªãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®èª­ã¿è¾¼ã¿
    if os.path.exists(MEMORY_FILE):
        try:
            with open(MEMORY_FILE, "r", encoding="utf-8") as f:
                memory = json.load(f)
            concepts = memory.get("concepts", [])
            for concept in concepts:
                attributes = concept.get("attributes", {})
                tracked = attributes.get("tracked_keywords")
                if isinstance(tracked, list) and tracked:
                    # æ—¥æœ¬èªã‚³ãƒ¡ãƒ³ãƒˆ: è¨˜æ†¶ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’åˆ©ç”¨
                    return [str(kw) for kw in tracked if str(kw).strip()]
        except Exception as exc:  # pylint: disable=broad-except
            print(f"âš ï¸ ãƒ¡ãƒ¢ãƒªãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {exc}")

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    return DEFAULT_KEYWORDS


def fetch_google_results(keyword: str) -> Dict[str, Any]:
    """Googleã‚«ã‚¹ã‚¿ãƒ æ¤œç´¢APIã‚’ç”¨ã„ã¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å¯è¦–æ€§ã‚’å–å¾—"""

    api_key = os.getenv("GOOGLE_API_KEY")
    cx = os.getenv("GOOGLE_CX")
    if not api_key or not cx:
        raise RuntimeError("Google APIã‚­ãƒ¼ã¾ãŸã¯æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³IDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

    params = {
        "key": api_key,
        "cx": cx,
        "q": keyword,
        "num": 3,
    }

    response = requests.get(
        "https://www.googleapis.com/customsearch/v1",
        params=params,
        timeout=30,
    )
    response.raise_for_status()
    return response.json()


def parse_results(data: Dict[str, Any]) -> Dict[str, Any]:
    """APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰CSVä¿å­˜ç”¨ã®æƒ…å ±ã‚’æŠ½å‡º"""

    total_results = int(data.get("searchInformation", {}).get("totalResults", 0))
    items = data.get("items", [])

    def build_entry(index: int) -> SearchResult:
        if index < len(items):
            item = items[index]
            return SearchResult(title=item.get("title", ""), url=item.get("link", ""))
        return SearchResult(title="", url="")

    top_entries = [build_entry(i) for i in range(3)]
    return {
        "totalResults": total_results,
        "top_entries": top_entries,
    }


def ensure_log_header(path: str) -> None:
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ä½œæˆ"""

    if not os.path.exists(path):
        header = [
            "timestamp",
            "keyword",
            "totalResults",
            "top1_title",
            "top1_url",
            "top2_title",
            "top2_url",
            "top3_title",
            "top3_url",
        ]
        with open(path, "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(header)


def append_visibility_rows(rows: List[Dict[str, Any]]) -> None:
    """æ–°ã—ã„å¯è¦–æ€§ãƒ‡ãƒ¼ã‚¿ã‚’CSVã«è¿½è¨˜"""

    ensure_log_header(VISIBILITY_LOG)
    with open(VISIBILITY_LOG, "a", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        for row in rows:
            writer.writerow(
                [
                    row["timestamp"],
                    row["keyword"],
                    row["totalResults"],
                    row["top_entries"][0].title,
                    row["top_entries"][0].url,
                    row["top_entries"][1].title,
                    row["top_entries"][1].url,
                    row["top_entries"][2].title,
                    row["top_entries"][2].url,
                ]
            )


def load_dataframe() -> pd.DataFrame:
    """visibility_log.csvã‚’DataFrameã¨ã—ã¦èª­ã¿è¾¼ã‚€"""

    if not os.path.exists(VISIBILITY_LOG):
        raise FileNotFoundError(f"{VISIBILITY_LOG} ãŒå­˜åœ¨ã—ã¾ã›ã‚“")

    df = pd.read_csv(VISIBILITY_LOG)
    df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce")
    df = df.dropna(subset=["timestamp", "keyword"])
    df["totalResults"] = pd.to_numeric(df["totalResults"], errors="coerce").fillna(0)
    return df


def generate_trend_chart(df: pd.DataFrame) -> None:
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã”ã¨ã®æ™‚ç³»åˆ—æ¨ç§»ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ"""

    trend_df = (
        df.sort_values("timestamp")
        .pivot_table(index="timestamp", columns="keyword", values="totalResults", aggfunc="last")
    )
    trend_df = trend_df.fillna(method="ffill")

    plt.figure(figsize=(10, 6))
    for keyword in trend_df.columns:
        plt.plot(trend_df.index, trend_df[keyword], marker="o", label=keyword)

    plt.title("AIEO Visibility Trend (6-hour cadence)")
    plt.xlabel("Timestamp (UTC)")
    plt.ylabel("Google totalResults")
    plt.grid(True, linestyle="--", alpha=0.4)
    plt.legend()
    plt.tight_layout()
    plt.savefig(TREND_CHART)
    plt.close()


def generate_growth_chart(df: pd.DataFrame) -> None:
    """ç›´è¿‘ã®æˆé•·ç‡ï¼ˆÎ”totalResultsï¼‰ã‚’æ£’ã‚°ãƒ©ãƒ•ã§å‡ºåŠ›"""

    latest = df.sort_values("timestamp").groupby("keyword").tail(2)

    growth_data = []
    for keyword, group in latest.groupby("keyword"):
        if len(group) == 1:
            change = group.iloc[0]["totalResults"]
        else:
            prev, curr = group.iloc[0], group.iloc[1]
            change = curr["totalResults"] - prev["totalResults"]
        growth_data.append((keyword, change))

    growth_data.sort(key=lambda x: x[1], reverse=True)

    plt.figure(figsize=(8, 5))
    keywords = [item[0] for item in growth_data]
    changes = [item[1] for item in growth_data]
    bars = plt.barh(keywords, changes, color="#007BFF")
    plt.title("AIEO Visibility Growth (last interval)")
    plt.xlabel("Î” totalResults")
    plt.grid(axis="x", linestyle="--", alpha=0.3)

    for bar, change in zip(bars, changes):
        plt.text(bar.get_width(), bar.get_y() + bar.get_height() / 2, f" {int(change)}", va="center")

    plt.tight_layout()
    plt.savefig(GROWTH_CHART)
    plt.close()


def generate_resonance_chart(df: pd.DataFrame) -> None:
    """æœ€æ–°ã®å¯è¦–æ€§ã‚¹ã‚³ã‚¢ã‚’å…±é³´ãƒãƒ£ãƒ¼ãƒˆã¨ã—ã¦ä¿å­˜"""

    latest = df.sort_values("timestamp").groupby("keyword").tail(1)
    latest = latest.sort_values("totalResults", ascending=True)

    plt.figure(figsize=(8, 6))
    plt.barh(latest["keyword"], latest["totalResults"], color="#00AEEF")
    plt.title("AIEO Resonance Visibility Snapshot")
    plt.xlabel("Google totalResults")
    plt.tight_layout()
    plt.savefig(RESonANCE_CHART)
    plt.close()


def run_visibility_pulse() -> None:
    """å¯è¦–æ€§è¨ˆæ¸¬ã‹ã‚‰ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆã¾ã§ã®ãƒ¡ã‚¤ãƒ³å‡¦ç†"""

    keywords = load_keywords()
    timestamp = datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%S")
    collected_rows: List[Dict[str, Any]] = []

    print(f"ğŸš€ Visibility Pulse started at {timestamp} UTC")
    print(f"ğŸ¯ Tracking {len(keywords)} keywords: {', '.join(keywords)}")

    for keyword in keywords:
        try:
            print(f"ğŸ” Fetching visibility for '{keyword}'...")
            raw_data = fetch_google_results(keyword)
            parsed = parse_results(raw_data)
            collected_rows.append(
                {
                    "timestamp": timestamp,
                    "keyword": keyword,
                    "totalResults": parsed["totalResults"],
                    "top_entries": parsed["top_entries"],
                }
            )
            print(f"   âœ… totalResults = {parsed['totalResults']}")
        except Exception as exc:  # pylint: disable=broad-except
            print(f"   âŒ Failed to fetch '{keyword}': {exc}")

    if not collected_rows:
        raise RuntimeError("å¯è¦–æ€§ãƒ‡ãƒ¼ã‚¿ãŒ1ä»¶ã‚‚å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

    append_visibility_rows(collected_rows)
    print(f"ğŸ“ Appended {len(collected_rows)} rows to {VISIBILITY_LOG}")

    df = load_dataframe()
    generate_trend_chart(df)
    generate_growth_chart(df)
    generate_resonance_chart(df)
    print("ğŸ“ˆ Charts updated: visibility, growth, resonance")

    latest_snapshot = {row["keyword"]: row["totalResults"] for row in collected_rows}
    print("\nğŸ“Š Latest snapshot:")
    for keyword, total in latest_snapshot.items():
        print(f" - {keyword}: {total}")

    print("\nâœ… Visibility Pulse completed successfully.")


if __name__ == "__main__":
    run_visibility_pulse()
