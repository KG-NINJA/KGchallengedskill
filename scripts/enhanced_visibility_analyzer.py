#!/usr/bin/env python3
"""
Enhanced AIEO Visibility Analyzer
visibility_log.csvã‹ã‚‰ã‚ˆã‚Šè©³ç´°ãªåˆ†æžã‚’è¡Œã†
"""

import csv
import os
from datetime import datetime
from collections import defaultdict
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates

LOG_FILE = "visibility_log.csv"
CHART_FILE = "visibility_detailed_analysis.png"

def load_and_clean_data():
    """CSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
    if not os.path.exists(LOG_FILE):
        print(f"âŒ {LOG_FILE} not found")
        return None
    
    data = []
    with open(LOG_FILE, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            # ä¸æ­£ãªè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæ•°å€¤ã ã‘ã®è¡Œãªã©ï¼‰
            if row.get('keyword') and not row['keyword'].isdigit():
                data.append(row)
    
    return data

def analyze_keyword_performance(data):
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ¥ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹åˆ†æž"""
    keyword_stats = defaultdict(lambda: {
        'checks': 0,
        'total_results': [],
        'top1_urls': [],
        'top2_urls': [],
        'top3_urls': [],
        'timestamps': []
    })
    
    for row in data:
        keyword = row['keyword']
        keyword_stats[keyword]['checks'] += 1
        keyword_stats[keyword]['timestamps'].append(row['timestamp'])
        
        # æ¤œç´¢çµæžœæ•°ã®è¨˜éŒ²
        try:
            total = int(row.get('totalResults', 0))
            keyword_stats[keyword]['total_results'].append(total)
        except (ValueError, TypeError):
            pass
        
        # Top URLsã®è¨˜éŒ²
        for i in range(1, 4):
            url = row.get(f'top{i}_url', '')
            if url:
                keyword_stats[keyword][f'top{i}_urls'].append(url)
    
    return keyword_stats

def check_own_content(url, own_domains=['x.com/FuwaCocoOwnerKG', 'twitter.com/FuwaCocoOwnerKG', 
                                        'github.com/KG-NINJA', 'pinterest.com/kgninja', 
                                        'instagram.com/kgninja']):
    """è‡ªåˆ†ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã©ã†ã‹ãƒã‚§ãƒƒã‚¯"""
    url_lower = url.lower()
    return any(domain.lower() in url_lower for domain in own_domains)

def calculate_visibility_score(stats):
    """å¯è¦–æ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆè‡ªåˆ†ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒTop3ã«ä½•å›žå…¥ã£ãŸã‹ï¼‰"""
    own_content_count = 0
    total_checks = stats['checks'] * 3  # Top3 x ãƒã‚§ãƒƒã‚¯å›žæ•°
    
    for i in range(1, 4):
        urls = stats[f'top{i}_urls']
        own_content_count += sum(1 for url in urls if check_own_content(url))
    
    return (own_content_count / total_checks * 100) if total_checks > 0 else 0

def print_detailed_analysis(keyword_stats):
    """è©³ç´°åˆ†æžã‚’è¡¨ç¤º"""
    print("\n" + "="*80)
    print("ðŸ“Š DETAILED KEYWORD ANALYSIS")
    print("="*80)
    
    # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
    sorted_keywords = sorted(
        keyword_stats.items(),
        key=lambda x: calculate_visibility_score(x[1]),
        reverse=True
    )
    
    for keyword, stats in sorted_keywords:
        visibility_score = calculate_visibility_score(stats)
        
        print(f"\n{'='*80}")
        print(f"ðŸ”‘ {keyword}")
        print(f"{'='*80}")
        
        # åŸºæœ¬çµ±è¨ˆ
        print(f"ðŸ“ˆ Total Checks: {stats['checks']}")
        
        if stats['total_results']:
            avg_results = sum(stats['total_results']) / len(stats['total_results'])
            print(f"ðŸ“Š Avg Search Results: {avg_results:,.0f}")
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æž
            if len(stats['total_results']) >= 2:
                first = stats['total_results'][0]
                last = stats['total_results'][-1]
                change = ((last - first) / first * 100) if first > 0 else 0
                trend = "ðŸ“ˆ" if change > 0 else "ðŸ“‰"
                print(f"{trend} Results Trend: {change:+.1f}%")
        
        # å¯è¦–æ€§ã‚¹ã‚³ã‚¢
        print(f"\nðŸŽ¯ Visibility Score: {visibility_score:.1f}%")
        
        # è‡ªåˆ†ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å‡ºç¾é »åº¦
        own_content_appearances = {
            'Top 1': sum(1 for url in stats['top1_urls'] if check_own_content(url)),
            'Top 2': sum(1 for url in stats['top2_urls'] if check_own_content(url)),
            'Top 3': sum(1 for url in stats['top3_urls'] if check_own_content(url))
        }
        
        print("\nðŸ“ Your Content Appearances:")
        for position, count in own_content_appearances.items():
            percentage = (count / stats['checks'] * 100) if stats['checks'] > 0 else 0
            print(f"   {position}: {count}/{stats['checks']} ({percentage:.1f}%)")
        
        # æœ€ã‚‚å¤šãè¡¨ç¤ºã•ã‚ŒãŸURL
        print("\nðŸ”— Most Common URLs:")
        for i in range(1, 4):
            urls = stats[f'top{i}_urls']
            if urls:
                # URLã®å‡ºç¾å›žæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                url_counts = defaultdict(int)
                for url in urls:
                    url_counts[url] += 1
                
                # æœ€ã‚‚å¤šã„URLã‚’å–å¾—
                most_common = max(url_counts.items(), key=lambda x: x[1])
                url, count = most_common
                own_marker = "âœ… (YOUR CONTENT)" if check_own_content(url) else ""
                print(f"   Top {i}: {url[:60]}... ({count}/{stats['checks']}) {own_marker}")
        
        # æœŸé–“
        if stats['timestamps']:
            print(f"\nðŸ“… Period: {stats['timestamps'][0]} â†’ {stats['timestamps'][-1]}")

def visualize_trends(data):
    """ãƒˆãƒ¬ãƒ³ãƒ‰ã®å¯è¦–åŒ–"""
    df = pd.DataFrame(data)
    
    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’datetimeã«å¤‰æ›
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    df['totalResults'] = pd.to_numeric(df['totalResults'], errors='coerce')
    
    keywords = df['keyword'].unique()
    
    # 1ã¤ç›®ã®ã‚°ãƒ©ãƒ•: æ¤œç´¢çµæžœæ•°ã®æŽ¨ç§»
    fig, axes = plt.subplots(2, 1, figsize=(16, 10))
    
    # æ¤œç´¢çµæžœæ•°ã®æŽ¨ç§»
    ax1 = axes[0]
    for keyword in keywords:
        kw_data = df[df['keyword'] == keyword].sort_values('timestamp')
        if not kw_data.empty and kw_data['totalResults'].notna().any():
            ax1.plot(kw_data['timestamp'], kw_data['totalResults'], 
                    marker='o', label=keyword, linewidth=2, markersize=6)
    
    ax1.set_xlabel('Time', fontsize=12, fontweight='bold')
    ax1.set_ylabel('Total Search Results', fontsize=12, fontweight='bold')
    ax1.set_title('Search Results Volume Over Time', fontsize=14, fontweight='bold', pad=15)
    ax1.legend(loc='best', fontsize=9)
    ax1.grid(True, alpha=0.3)
    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d %H:%M'))
    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)
    
    # 2ã¤ç›®ã®ã‚°ãƒ©ãƒ•: å¯è¦–æ€§ã‚¹ã‚³ã‚¢ã®æŽ¨ç§»
    ax2 = axes[1]
    keyword_stats = analyze_keyword_performance(data)
    
    visibility_scores = []
    for keyword in keywords:
        score = calculate_visibility_score(keyword_stats[keyword])
        visibility_scores.append((keyword, score))
    
    visibility_scores.sort(key=lambda x: x[1], reverse=True)
    keywords_sorted = [k for k, _ in visibility_scores]
    scores = [s for _, s in visibility_scores]
    
    colors = ['#4CAF50' if s > 70 else '#FFC107' if s > 40 else '#F44336' for s in scores]
    bars = ax2.barh(keywords_sorted, scores, color=colors, alpha=0.7)
    
    ax2.set_xlabel('Visibility Score (%)', fontsize=12, fontweight='bold')
    ax2.set_ylabel('Keyword', fontsize=12, fontweight='bold')
    ax2.set_title('Visibility Score by Keyword (% of Your Content in Top 3)', 
                 fontsize=14, fontweight='bold', pad=15)
    ax2.grid(True, alpha=0.3, axis='x')
    ax2.set_xlim(0, 100)
    
    # å€¤ã‚’ãƒãƒ¼ã«è¡¨ç¤º
    for i, (bar, score) in enumerate(zip(bars, scores)):
        ax2.text(score + 2, i, f'{score:.1f}%', 
                va='center', fontweight='bold', fontsize=10)
    
    plt.tight_layout()
    
    try:
        plt.savefig(CHART_FILE, dpi=150, bbox_inches='tight')
        print(f"\nâœ… Visualization saved: {CHART_FILE}")
    except Exception as e:
        print(f"\nâŒ Error saving chart: {e}")
    finally:
        plt.close()

def generate_recommendations(keyword_stats):
    """æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ"""
    print("\n" + "="*80)
    print("ðŸ’¡ RECOMMENDATIONS")
    print("="*80)
    
    # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
    sorted_keywords = sorted(
        keyword_stats.items(),
        key=lambda x: calculate_visibility_score(x[1]),
        reverse=True
    )
    
    print("\nðŸ† STRENGTHS (Keep doing what you're doing!):")
    for keyword, stats in sorted_keywords[:2]:
        score = calculate_visibility_score(stats)
        if score > 50:
            print(f"   âœ… {keyword}: {score:.1f}% visibility")
            print(f"      â†’ Your content dominates this keyword")
    
    print("\nðŸŽ¯ OPPORTUNITIES (Focus your efforts here):")
    for keyword, stats in sorted_keywords[-2:]:
        score = calculate_visibility_score(stats)
        if score < 50:
            print(f"   âš ï¸  {keyword}: {score:.1f}% visibility")
            print(f"      â†’ Create more content around this keyword")
            
            # ç«¶åˆåˆ†æž
            top_competitors = set()
            for i in range(1, 4):
                for url in stats[f'top{i}_urls']:
                    if not check_own_content(url):
                        # ãƒ‰ãƒ¡ã‚¤ãƒ³æŠ½å‡º
                        if '//' in url:
                            domain = url.split('//')[1].split('/')[0]
                            top_competitors.add(domain)
            
            if top_competitors:
                print(f"      â†’ Main competitors: {', '.join(list(top_competitors)[:3])}")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("="*80)
    print("ðŸ” ENHANCED AIEO VISIBILITY ANALYZER")
    print("="*80)
    print(f"â° Analysis Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    data = load_and_clean_data()
    if not data:
        return
    
    print(f"âœ… Loaded {len(data)} records from {LOG_FILE}")
    
    # åˆ†æž
    keyword_stats = analyze_keyword_performance(data)
    print(f"âœ… Analyzing {len(keyword_stats)} keywords\n")
    
    # è©³ç´°åˆ†æžã‚’è¡¨ç¤º
    print_detailed_analysis(keyword_stats)
    
    # å¯è¦–åŒ–
    visualize_trends(data)
    
    # æŽ¨å¥¨äº‹é …
    generate_recommendations(keyword_stats)
    
    print("\n" + "="*80)
    print("âœ… Analysis Complete!")
    print("="*80)

if __name__ == "__main__":
    main()
